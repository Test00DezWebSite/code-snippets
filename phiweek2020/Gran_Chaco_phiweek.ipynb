{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESA EO $\\phi$- week 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous part of the session you have already gained experience in navigating around the Euro Data Cube interface and using **GeoDB**. Now, we are going to show a use case example to demonstrate how you can combine some of what you have learnt with **Sentinel Hub Services**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case Example: Deforestation in the Gran Chaco Region\n",
    "\n",
    "In this Jupyter Notebook we are going to investigate deforestation events happening in the Gran Chaco region that spans across parts of eastern Bolivia, western Paraguay, northern Argentina and a small part of the Brazilian state of Mato Grosso. The region has one of the highest rates of deforestation in the world, mainly linked to the expansion of cattle farming. \n",
    "\n",
    "The following articles provide more context information on the subject: [Deforestation in Argentinaâ€™s Gran Chaco\n",
    "](https://earthobservatory.nasa.gov/images/146731/deforestation-in-argentinas-gran-chaco), [Deforestation in Paraguay](https://earthobservatory.nasa.gov/images/92078/deforestation-in-paraguay), [WWF: Gran Chaco](https://www.worldwildlife.org/places/gran-chaco).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"deforestation.jpg\">\n",
    "Deforested parcels in the Gran Chaco forest region (credit: John Burton, WLT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Throughout the following examples we will see how to:\n",
    "\n",
    "- request satellite imagery using the Python wrapper to the Sentinel Hub API service\n",
    "- easily request metadata concerning images over a given area and time frame\n",
    "- extract basic statistical information for a given area and time frame\n",
    "\n",
    "First, we will access the [Global Forest Watch](http://www.globalforestwatch.org/about/) dataset (saved as a GeoDB in EDC) on deforestation in Gran Chaco. The original version can be downloaded [here](https://data.globalforestwatch.org/datasets/gran-chaco-deforestation). The dataset, that runs from 2011 to early 2018, represents deforested areas as polygons, derived manually using 30-meter resolution Landsat images for the 55 scenes that cover the Gran Chaco.\n",
    "\n",
    "To check the temporal and spatial accuracy of the polygons, we will select a small test subset in Paraguay and compare the polygons representing deforestation events in January 2018 to higher resolution Sentinel-2 images. In this section we will see how to query data using Sentinel Hub's python package, and how to get metadata from the Catalog API in order to select the correct images without wasting ressources / time. \n",
    "\n",
    "We will then show you how to use the brand-new datafusion capabilities of Sentinel Hub services to mitigate the drawbacks of using optical sensors for deforestation detection.\n",
    "\n",
    "Finally, we will investigate time series of Sentinel-2 images, deriving NDVI (Normalized Difference Vegetation Index) to see if the deforestation event can be automatically detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDC\n",
    "from edc import setup_environment_variables\n",
    "from xcube_geodb.core.geodb import GeoDBClient\n",
    "\n",
    "# Sentinel Hub Py\n",
    "from sentinelhub import (SHConfig, BBox, bbox_to_dimensions, CRS, SentinelHubRequest, DataSource, MimeType, FisRequest)\n",
    "from sentinelhub.geometry import Geometry\n",
    "\n",
    "# Utilities\n",
    "from pathlib import Path\n",
    "from oauthlib.oauth2 import BackendApplicationClient\n",
    "from requests_oauthlib import OAuth2Session\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Geographical libraries\n",
    "import geopandas\n",
    "from pyproj import Proj, transform\n",
    "from shapely.geometry import shape, box\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# Plotting\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import colors\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "# Rasterio\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import rasterio.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several options to setup your Sentinel Hub credentials, depending on how you want to access the services. In this workflow, as we will be working with the `sentinelhub-py` package to run requests in Python, we set up an `SHConfig` object that will take care of identification with the services for us. Therefore, we assign the identification parameters provided by EDC to the `SHConfig` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get identification parameters from EDC\n",
    "setup_environment_variables()\n",
    "\n",
    "# Setup SH services access\n",
    "config = SHConfig()\n",
    "\n",
    "config.sh_client_id = %env SH_CLIENT_ID\n",
    "config.sh_client_secret = %env SH_CLIENT_SECRET\n",
    "config.instance_id = %env SH_INSTANCE_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up access to the GeoDB, using `GeoDBClient` as shown in the previous section of this training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodb = GeoDBClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request a truecolor image as overview of the selected area\n",
    "\n",
    "Now that the credentials are set up, it is possible to request satellite images.\n",
    "\n",
    "We will start by plotting an overview True Color RBG image from Sentinel-2 of the area the we will be working on.\n",
    "\n",
    "The *Sentinel Hub Process API* will need the following information for a valid request:\n",
    "\n",
    "+ An **AOI** (area of interest): that contains the location's coordinates (polygon or bounding box). The image size is pre-calculated according to the resolution desired.\n",
    "+ **Evalscript** in which you specify the data products and their visualisation\n",
    "+ **Request body** with parameters about the location and time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define coordinates for area of interest and create a bbox object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the coordinates (lower-left, upper right) of our AOI\n",
    "aoi_bbox = [-60.28157336, -21.27560428, -60.12293070, -21.18495133]\n",
    "\n",
    "# Set AOI overview bbox\n",
    "resolution = 10\n",
    "aoi_overview = BBox(bbox=aoi_bbox, crs=CRS.WGS84)  # Make a BBox object of the list of coordinates\n",
    "aoi_overview_size = bbox_to_dimensions(aoi_overview, resolution=resolution)  # Automatically calculate the output size in px\n",
    "\n",
    "print(f\"Output image size: {aoi_overview_size[0]} * {aoi_overview_size[1]} px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalscript creation\n",
    "\n",
    "An [Evalscript](https://docs.sentinel-hub.com/api/latest/evalscript/v3/) is a piece of Javascript code that allows you to define the input and output paramters of the data you would like to query, as well as specifying the processing to be applied to the satellite images.\n",
    "\n",
    "For the evalscript you must specify at least the two following functions:\n",
    "\n",
    "+ setup function: this sets up the input (i.e. which bands to call) and output settings (number of bands to return, format, etc...).\n",
    "+ evaluatePixel function - this function is where you specify the processing (to derive new information from the images, or for visualisation) to be applied to the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following Evalscript, we want to return an RGB True Color image. In the `setup` function, we will specify that we want to use the Red (`B04`), Green (`B03`) and Blue (`B02`) bands of Sentinel-2. Since, we want a three-channel image (RGB), we specify that our output will have three bands. We use the convinient `AUTO` sample type for the returned data, as we are just going to visualise it. With `AUTO` values should range from 0-1, which will then automatically be stretched from the interval [0, 1] to [0, 255] and written into an UINT8 raster.\n",
    "\n",
    "Because the image would be too dark if we return directly the band values scaled from 0 to 255, we apply a gain (multiplying the values by 3.5). This is just for visualisation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_true_color = \"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "// Set up the input and output settings\n",
    "\n",
    "function setup() {\n",
    "  return {\n",
    "    input: [\"B02\", \"B03\", \"B04\"],  //define input bands\n",
    "    output: { bands: 3, sampleType: SampleType.AUTO}  //define amount of channels in output image (RGB = 3), and UINT16 format\n",
    "  };\n",
    "}\n",
    "\n",
    "// Map the input bands to the values in the output raster\n",
    "\n",
    "function evaluatePixel(sample) {\n",
    "  let gain = 3.5;\n",
    "  return [gain * sample.B04, gain * sample.B03, gain * sample.B02];    //map bands 4, 3, 2 to RGB channels and multiply by 3.5 for enhanced truecolor visualisation\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request body creation\n",
    "\n",
    "The run the Evalscript, we need to define the payload, or data parameters to send to Sentinel Hub Services. The Sentinel Hub python package simplifies the writing of the payload, by using the `SentinelHubRequest` class to pass the following input parameters:\n",
    "\n",
    "1. the created evalscript\n",
    "2. input data (data source and time interval)\n",
    "3. define the output (name and format)\n",
    "4. define bbox\n",
    "5. size of requested image\n",
    "6. identification with the SHConfig object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = SentinelHubRequest(evalscript=evalscript_true_color,\n",
    "                             input_data=[SentinelHubRequest.input_data(data_source=DataSource.SENTINEL2_L2A,\n",
    "                                                                       time_interval=(\"2017-12-31\",\n",
    "                                                                                      \"2017-12-31\"))],\n",
    "                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n",
    "                            bbox=aoi_overview,  \n",
    "                            size=aoi_overview_size,\n",
    "                            config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the request is created, we just need to run it using the `get_data` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = request.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the requested image\n",
    "\n",
    "By using `get_data` without any additional parameters saved the results to the `overview` variable. Let's plot it to look at the returned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,10))\n",
    "ax.imshow(overview[0])\n",
    "\n",
    "# Plot configuration\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"2017-12-31\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quizz: can you figure out how to request a falsecolor infrared image?\n",
    "Try to fill in the gaps in the evalscript below.\n",
    "\n",
    "*Hint: To receive a falsecolor infrared image you need to map Sentinel-2 Band 8 (NIR) to the red channel, Band 4 (RED) to the green channel, and Band 3 (GREEN) to the blue channel*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_false_color = \"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "function setup() {\n",
    "  return {\n",
    "    input: [\"\", \"\", \"\"],\n",
    "    output: { bands: 3 }\n",
    "  };\n",
    "}\n",
    "\n",
    "function evaluatePixel(sample) {\n",
    "  let gain = 2.5;\n",
    "  return [ , , ];\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following cell for the solution. Make sure to run the following cell twice, one time for fetching the solution and a second time for running the Evalscript.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/sentinel-hub/code-snippets/master/phiweek2020/Solution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the Evalscript, let's run the request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = SentinelHubRequest(evalscript=evalscript_false_color,\n",
    "                             input_data=[SentinelHubRequest.input_data(data_source=DataSource.SENTINEL2_L2A,\n",
    "                                                                       time_interval=(\"2017-12-31\",\n",
    "                                                                                      \"2017-12-31\"))],\n",
    "                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n",
    "                            bbox=aoi_overview,  \n",
    "                            size=aoi_overview_size,\n",
    "                            config=config)\n",
    "\n",
    "overview_fc = request.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the False Color image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,10))\n",
    "ax.imshow(overview_fc[0])\n",
    "\n",
    "# Plot configuration\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"2017-12-31\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the collection from GeoDB and data preparation\n",
    "In the next step we retrieve the prepared gran_chaco collection from GeoDB.\n",
    "\n",
    "As a reminder, you can explore the original dataset [here](https://data.globalforestwatch.org/datasets/gran-chaco-deforestation/data?geometry=-60.601%2C-20.023%2C-59.293%2C-19.797)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check available collections in GeoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `geodb` client, let's look at what collections are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get already existing collections\n",
    "geodb.get_my_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the collection by bbox to retrieve only the area we are interested in\n",
    "\n",
    "We are interested in the `gran_chaco` GeoDB collection. However, we will not query it entirely in this exercise since we are only interested in a specific AOI that we defined further up. Therefore, not needing the whole dataset, we only retrieve the polygons that are contained in our area of interest by querying the dataset with our defined bbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gran_chaco = geodb.get_collection_by_bbox('gran_chaco', database=\"phi_week\", bbox=aoi_bbox, bbox_crs=4326, comparison_mode=\"contains\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preview the collection subset that we have just queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gran_chaco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "As we can see above, in the subset of the GeoDB that we queried, there are deforestation events detected in 2011, 2014, 2015, 2016, 2017 and 2018. Let's narrow down the dataset a little further and only select the polygons in 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we convert the date strings to `datetime` objects to make the querying easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dates to datetime objects and store in a new column\n",
    "gran_chaco[\"datetime\"] = pd.to_datetime(gran_chaco[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only polygons from 2018\n",
    "gran_chaco_subset_2018 = gran_chaco[gran_chaco[\"datetime\"].dt.year == 2018]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can preview the subset that we have selected based on the year 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gran_chaco_subset_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all selected polygons\n",
    "IPython.display.GeoJSON(gran_chaco_subset_2018.__geo_interface__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun fact: thanks to Ipython, it is easy to zoom out to have an idea of the location of the polygons. Furthermore, you can click on an individual polygon to list the attributes of that specific shape in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Catalog API for dates with  available Sentinel-2 data before and after the registered deforestation event\n",
    "\n",
    "For our selected AOI, we will check if the registered deforestation date in the dataset that we are querying is correct. To do so, we will look at the closest cloud-free Sentinel images before and after the date assigned to the polygon (here, `2018-01-31`).\n",
    "\n",
    "Rather than query all the Sentinel-2 images in a given time period around the date of interest, which would be a waste of ressources particularly in cloudy areas, we can use the Catalog API service to list metadata about the images that will guide our choice in the selection. The Catalog service allows us to return the dates of images intersecting the AOI, but other essential parameters, such as the scene's overall cloud cover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an OAuth2 session and create a token for it\n",
    "In order to send a request to the Catalog API we need to create a token first. Let's start by creating an OAuth session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session\n",
    "client = BackendApplicationClient(client_id=%env SH_CLIENT_ID)\n",
    "oauth = OAuth2Session(client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The token acts like an ID we provide the API with to verify us as a registered user. This token is temporary (about 1h) for security reasons. If when running a Catalog request an authentification error is thrown, just execute the following cell again to obtain a new token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get token for the session\n",
    "token = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n",
    "                          client_id=%env SH_CLIENT_ID, client_secret=%env SH_CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Catalog API request\n",
    "We specify the service endpoint URL, set the Content-Type to 'application/json' because we only want to receive a list of dates with available Sentinel-2 data within the selected time period. We also set the `collection` that we want to query (here Sentinel-2 L1C), and the timerange we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Catalog API url\n",
    "catalog_url = \"https://services.sentinel-hub.com/api/v1/catalog/\"\n",
    "\n",
    "# Set the header\n",
    "headers = {\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Set the Catalog request parameters\n",
    "collections = \"sentinel-2-l1c\"\n",
    "datetime= \"2017-10-01T00:00:00Z/2018-02-15T23:59:59Z\"  # We set a wide time range to get an idea of the available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the catalog request\n",
    "response = oauth.request(\"GET\", f\"https://services.sentinel-hub.com/api/v1/catalog/collections/{collections}/items?bbox={aoi_bbox[0]},{aoi_bbox[1]},{aoi_bbox[2]},{aoi_bbox[3]}&datetime={datetime}&limit=20\", headers=headers)\n",
    "catalog_results = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the dates and cloud cover values\n",
    "available_data = []\n",
    "for entry in catalog_results[\"features\"]:\n",
    "    available_data.append((entry[\"properties\"][\"datetime\"], entry[\"properties\"][\"eo:cloud_cover\"]))\n",
    "    \n",
    "print(available_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the available dates\n",
    "\n",
    "We now have a list of images and their respective cloud cover available, we can filter out for the closest dates to the deforestation event marked in our database, taking in account the cloud cover. \n",
    "\n",
    "Let's select the images with less than 10% cloud cover over the entire scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the date of interest. Since all the dates are the same in our subset, we take the first one.\n",
    "deforestation_date = dt.strptime(gran_chaco_subset_2018.date.values[0], \"%Y-%m-%d\")\n",
    "\n",
    "# Cloud cover percentage filter\n",
    "cc = 10\n",
    "\n",
    "# We want to select the dates that have less than the set % of cloud cover\n",
    "available_datetimes = [dt.strptime(x[0], \"%Y-%m-%dT%H:%M:%SZ\") for x in available_data if x[1] <= cc]\n",
    "\n",
    "# Find the index before and after our date of interest\n",
    "past_dates = [date for date in available_datetimes if date < deforestation_date]\n",
    "future_dates = [date for date in available_datetimes if date >= deforestation_date]\n",
    "\n",
    "before_ind = available_datetimes.index(max(past_dates))\n",
    "after_ind = available_datetimes.index(min(future_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Closest date with less than {cc}% cloud cover. Before: {available_datetimes[before_ind]}; After: {available_datetimes[after_ind]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Sentinel-2 images\n",
    "\n",
    "Now we have the dates that we are interested in, we will query the images using `sentinelhub-py`, as we did for the True Color and False Color RGB images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set the bounding box to cover our selected field based on the geometry of the object in the database. We will set a buffer to make sure that we cover the entire set of polygons. Note that the buffer values are in degrees since the coordinates are in `WGS84`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set AOI bounding box for our example field and image size according to desired resolution\n",
    "resolution = 10\n",
    "aoi = BBox(bbox=box(*gran_chaco_subset_2018.total_bounds).buffer(0.001).bounds, crs=CRS.WGS84)\n",
    "aoi_size = bbox_to_dimensions(aoi, resolution=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our request, we will do things a little differently from the previous requests. Indeed, to be able to plot the extent of the field on our image, we need it to be georeferenced. Therefore, using the numpy array returned when calling the request is not sufficient. To get a georeferenced image, we will save the response as a `geotiff` locally, then open it with a geospatial library later (here we will use `rasterio`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make two requests: one for the date before the event, that we selected earlier, and one after. Before each request, we make a directory to save the `geotiff`s and set the `save_data` parameter to `True` in the `get_data` method. Note, make sure that you delete any previous requests in the folders (if they exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory to save the response\n",
    "Path('./results/before').mkdir(parents=True, exist_ok=True)\n",
    "  \n",
    "request = SentinelHubRequest(evalscript=evalscript_true_color,\n",
    "                             input_data=[SentinelHubRequest.input_data(data_source=DataSource.SENTINEL2_L2A,\n",
    "                                                                       time_interval=(dt.strftime(available_datetimes[before_ind], \"%Y-%m-%d\"),\n",
    "                                                                                      dt.strftime(available_datetimes[before_ind], \"%Y-%m-%d\")))],\n",
    "                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n",
    "                            bbox=aoi,  \n",
    "                            size=aoi_size,\n",
    "                            data_folder='./results/before/',\n",
    "                            config=config)\n",
    "\n",
    "true_color_before = request.get_data(save_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory to save the response\n",
    "Path('./results/after').mkdir(parents=True, exist_ok=True)\n",
    "  \n",
    "request = SentinelHubRequest(evalscript=evalscript_true_color,\n",
    "                             input_data=[SentinelHubRequest.input_data(data_source=DataSource.SENTINEL2_L2A,\n",
    "                                                                       time_interval=(dt.strftime(available_datetimes[after_ind], \"%Y-%m-%d\"),\n",
    "                                                                                      dt.strftime(available_datetimes[after_ind], \"%Y-%m-%d\")))],\n",
    "                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n",
    "                            bbox=aoi,  \n",
    "                            size=aoi_size,\n",
    "                            data_folder='./results/after/',\n",
    "                            config=config)\n",
    "\n",
    "true_color_after = request.get_data(save_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have downloaded the data, let's fetch the path to the resulting `geotiff`s and open them with rasterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get folder name created\n",
    "fld_a = [f for f in Path(\"./results/before/\").iterdir() if f.is_dir()][0]\n",
    "fld_b = [f for f in Path(\"./results/after/\").iterdir() if f.is_dir()][0]\n",
    "\n",
    "# Open raster with Rasterio\n",
    "raster_before = rasterio.open(str(fld_a.joinpath(\"response.tiff\")))\n",
    "raster_after = rasterio.open(str(fld_b.joinpath(\"response.tiff\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the raster images saved locally and show the outline of the selected field in the database\n",
    "\n",
    "Here will plot the georeferenced rasterio rasters and add the field outlines over the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(18, 10))\n",
    "\n",
    "# Plot images before and after\n",
    "show(raster_before, ax=ax)\n",
    "show(raster_after, ax=ax1)\n",
    "\n",
    "# Plot the field outline over the images\n",
    "gran_chaco_subset_2018.plot(ax=ax, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "gran_chaco_subset_2018.plot(ax=ax1, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "\n",
    "# Plot configuration\n",
    "for axs in [ax, ax1]:\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "\n",
    "ax.set_title(dt.strftime(available_datetimes[before_ind], \"%Y-%m-%d\"))\n",
    "ax1.set_title(dt.strftime(available_datetimes[after_ind], \"%Y-%m-%d\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image above, we notice several points:\n",
    "\n",
    "1. For some of the smaller polygons we can see that the deforestation happened between the 31<sup>st</sup> December 2017 and 4<sup>th</sup> February 2018. Due to cloud coverage, we cannot narrow down the date any more. But we will get back to this point later in the process.\n",
    "\n",
    "2. The larger polygons that were identified as deforested in January 2018 in the dataset were already partly deforested in December 2017.\n",
    "\n",
    "3. Certain areas delimited manually based on the Landsat images seems shifted compared to the Sentinel-2 images: i.e. the large polygon top centre. This shift may be due to the difference in resolution or slight geolocalisation differences between the sensors.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Landsat imagery\n",
    "\n",
    "To see the field delination on a Landsat image, we can query a Landsat image as we did for Sentinel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quizz: what is the easiest way to write an Evalscript for Landsat True Color?\n",
    "\n",
    "Based on Landsat [bands](https://docs.sentinel-hub.com/api/latest/data/landsat-8/) available, how would you return a True Color image using the Evalscript?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_landsat_true_color = \"\"\"\"\"\"\n",
    "\n",
    "# Adjust the image size for the change in resolution\n",
    "aoi_size_landsat = bbox_to_dimensions(aoi, resolution=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following cell for the solution. Make sure to run the following cell twice, one time for fetching the solution and a second time for running the Evalscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/sentinel-hub/code-snippets/master/phiweek2020/Solution2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus question: how would you improve the resolution of the True Color image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_landsat_true_color_improved = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following cell for the solution. Make sure to run the following cell twice, one time for fetching the solution and a second time for running the Evalscript.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/sentinel-hub/code-snippets/master/phiweek2020/Solution3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the query (using the evalscript of your choice) for two dates that were preselected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory to save the request\n",
    "Path('./results/landsat/before').mkdir(parents=True, exist_ok=True)\n",
    "  \n",
    "request = SentinelHubRequest(evalscript=evalscript_landsat_true_color,\n",
    "                             input_data=[SentinelHubRequest.input_data(data_source=DataSource.LANDSAT8_L1C,\n",
    "                                                                       time_interval=(\"2017-12-16\",\n",
    "                                                                                      \"2017-12-16\"))],\n",
    "                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n",
    "                            bbox=aoi,  \n",
    "                            size=aoi_size_landsat,\n",
    "                            data_folder='./results/landsat/before',\n",
    "                            config=config)\n",
    "\n",
    "true_color_landsat= request.get_data(save_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory to save the request\n",
    "Path('./results/landsat/after').mkdir(parents=True, exist_ok=True)\n",
    "  \n",
    "request = SentinelHubRequest(evalscript=evalscript_landsat_true_color,\n",
    "                             input_data=[SentinelHubRequest.input_data(data_source=DataSource.LANDSAT8_L1C,\n",
    "                                                                       time_interval=(\"2018-01-17\",\n",
    "                                                                                      \"2018-01-17\"))],\n",
    "                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n",
    "                            bbox=aoi,  \n",
    "                            size=aoi_size_landsat,\n",
    "                            data_folder='./results/landsat/after',\n",
    "                            config=config)\n",
    "\n",
    "true_color_landsat= request.get_data(save_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did for Sentinel-2, fetch the latest folder and open the image with Rasterio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get folder name created\n",
    "fld_lb = [f for f in Path(\"./results/landsat/before\").iterdir() if f.is_dir()][0]\n",
    "fld_la = [f for f in Path(\"./results/landsat/after\").iterdir() if f.is_dir()][0]\n",
    "\n",
    "# Open raster with Rasterio\n",
    "raster_landsat_before = rasterio.open(str(fld_lb.joinpath(\"response.tiff\")))\n",
    "raster_landsat_after = rasterio.open(str(fld_la.joinpath(\"response.tiff\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Landsat scene saved locally and show the outline of the selected field in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(18, 10))\n",
    "\n",
    "# Plot images before and after\n",
    "show(raster_landsat_before, ax=ax)\n",
    "show(raster_landsat_after, ax=ax1)\n",
    "\n",
    "# Plot the field outline over the images\n",
    "gran_chaco_subset_2018.plot(ax=ax, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "gran_chaco_subset_2018.plot(ax=ax1, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "\n",
    "# Plot configuration\n",
    "for axs in [ax, ax1]:\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "\n",
    "ax.set_title(\"2017-12-16\")\n",
    "ax1.set_title(\"2018-01-17\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the Landsat images in December 2017 and Janauary 2018, provides more information on how the polygons were delineated. Indeed, owing to the revisit time of Landsat (14 days) and cloud cover, some of the deforestation events that happened end of December 2017 (as we saw in the Sentinel-2 images) were missed. The Landsat acquisition on 17<sup>th</sup> January 2018 provides more insight in the timing of the deforestation. Nevertheless, two of the polygon were already partly deforested in December 2017, which could mean that the dataset contains operator errors. The images also show that the 31<sup>st</sup> January 2018 indicated in the dataset is an arbotrary date representing the entire month of January."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Filling in the Gaps\" or how to use data fusion to mitigate gaps in optical imagery time series\n",
    "\n",
    "In the previous section, we were able to fetch Sentinel-2 images to observe deforestation events. However, in January all the scenes acquired were completely cloud covered. As a recap, let's just look at cloud cover for that time of year using the previous catalog request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18, 10))\n",
    "\n",
    "# Plot the cloud cover for available dates\n",
    "ax.plot([dt.strptime(x[0], \"%Y-%m-%dT%H:%M:%SZ\") for x in available_data], [x[1] for x in available_data], marker='o',\n",
    "        markersize=12, linestyle=\"none\", color=\"black\")\n",
    "\n",
    "# Highligh January\n",
    "ax.fill_between((dt.strptime(\"2018-01-01\", \"%Y-%m-%d\"), dt.strptime(\"2018-01-31\", \"%Y-%m-%d\")), (0,0), (100,100), color=\"red\", alpha=0.3)\n",
    "\n",
    "# Plot 5% level\n",
    "ax.plot([dt.strptime(x[0], \"%Y-%m-%dT%H:%M:%SZ\") for x in available_data], [10 for x in available_data], linestyle=\"--\", linewidth=2, color=\"black\")\n",
    "\n",
    "# Plot configuration\n",
    "ax.set_ylim(0,100)\n",
    "ax.set_ylabel(\"Cloud cover percentage\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also know that the deforestation happened before the 17<sup>th</sup> January 2018, when looking at the Landsat image. But is there any way of checking with an other satellite platform that isn't affected by clouds?\n",
    "\n",
    "By combining optical imagery with SAR (Synthetic Aperture Radar), the shortcomings of cloud cover can be (partly) mitigated. In this example, we will use Sentinel-1 images. Although the revisit frequency of Sentinel-1 is similar to Sentinel-2 (approximately 6 days at the equator), the additional data may be used to increase the temporal resolution of time-series regardless of local atmospheric conditions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datafusion\n",
    "\n",
    "We recently wrote a [blog post](https://medium.com/sentinel-hub/data-fusion-combine-satellite-datasets-to-unlock-new-possibilities-26356c481169) about the new datafusion capabilities of Sentinel Hub services. Here, we will combine Sentinel-2 and Sentinel-1 images to detect deforestation event that happened in January."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will use the Catalog API service again to obtain the list of available Sentinel-1 acquisitions in January 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Catalog API url\n",
    "catalog_url = \"https://services.sentinel-hub.com/api/v1/catalog/\"\n",
    "\n",
    "# Set the header\n",
    "headers = {\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Set the Catalog request parameters\n",
    "collections = \"sentinel-1-grd\"  # This time, we use the Sentinel 1 collection\n",
    "datetime= \"2018-01-01T00:00:00Z/2018-01-31T23:59:59Z\"  # Time range over January 2018\n",
    "\n",
    "# Run the catalog request\n",
    "response = oauth.request(\"GET\", f\"https://services.sentinel-hub.com/api/v1/catalog/collections/{collections}/items?bbox={aoi_bbox[0]},{aoi_bbox[1]},{aoi_bbox[2]},{aoi_bbox[3]}&datetime={datetime}&limit=20\", headers=headers)\n",
    "catalog_results = response.json()\n",
    "\n",
    "# Fetch the dates and write to a list\n",
    "s1_dates = []\n",
    "\n",
    "for entry in catalog_results[\"features\"]:\n",
    "    s1_dates.append(entry[\"properties\"][\"datetime\"])\n",
    "    \n",
    "print(s1_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Catalog service API, we see that there are 6 images available for Janauary 2018.\n",
    "\n",
    "### Evalscript\n",
    "\n",
    "In the following Evalscript we will perform the following steps for each pixel in the image:\n",
    "\n",
    "+ check if the pixel's NDVI (see below) value has dropped between December and February. If it hasn't, we will assume there was no deforestation in January and return the Sentinel-2 True Color RGB.\n",
    "+ if the NDVI has dropped from above 0.4 to below 0.4 (an empirical threshold that we set), we then look at the backscatter between different Sentinel-1 dates.\n",
    "+ if the drop in backscatter from a date to another is larger than a given value (once again empirically determined), then we return a color according to the date.\n",
    "\n",
    "To perform the operations in the list above, we need:\n",
    "\n",
    "- the closest cloud-free Sentinel-2 image before January\n",
    "- the closest cloud-free Sentinel-2 image after January\n",
    "- all Sentinel-1 images in January"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**NDVI (Normalized difference vegetation index)**\n",
    "\n",
    "_The well known and widely used NDVI is a simple, but effective index for quantifying green vegetation. It normalizes green leaf scattering in Near Infra-red wavelengths with chlorophyll absorption in red wavelengths._\n",
    "\n",
    "_The value range of the NDVI is -1 to 1. Negative values of NDVI (values approaching -1) correspond to water. Values close to zero (-0.1 to 0.1) generally correspond to barren areas of rock, sand, or snow. Low, positive values represent shrub and grassland (approximately 0.2 to 0.4), while high values indicate temperate and tropical rainforests (values approaching 1)._<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we color coded the changes as follows:\n",
    "\n",
    "2018-01-01 -> 2018-01-02 = ORANGE\n",
    "\n",
    "\n",
    "2018-01-02 -> 2018-01-13 = WHITE\n",
    "\n",
    "\n",
    "2018-01-13 -> 2018-01-14 = BLUE\n",
    "\n",
    "\n",
    "2018-01-14 -> 2018-01-25 = GREEN\n",
    "\n",
    "\n",
    "2018-01-25 -> 2018-01-26 = RED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_data_fusion = \"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "function setup (){\n",
    "  return {\n",
    "    input: [\n",
    "      {datasource: \"s1\", bands:[\"VH\"]},\n",
    "      {datasource: \"s2_before\", bands:[\"B02\", \"B03\", \"B04\", \"B08\"]},\n",
    "      {datasource: \"s2_after\", bands:[\"B02\", \"B03\", \"B04\", \"B08\"]}],\n",
    "    output: [\n",
    "      {id: \"default\", bands: 3}\n",
    "    ],\n",
    "    mosaicking: \"ORBIT\"\n",
    "  };\n",
    "}\n",
    "  \n",
    "// visualizes decibels from -20 to 0\n",
    "function toDb(linear) {\n",
    "  // the following commented out lines are simplified below\n",
    "  // var log = 10 * Math.log(linear) / Math.LN10\n",
    "  // var val = Math.max(0, (log + 20) / 20)\n",
    "  return Math.max(0, Math.log(linear) * 0.21714724095 + 1)\n",
    "}\n",
    "  \n",
    "function evaluatePixel(samples, scenes) {\n",
    "\n",
    "  // Get samples from different specified datasources\n",
    "  var s1 = samples.s1;\n",
    "  var s2before = samples.s2_before[0];\n",
    "  var s2after = samples.s2_after[0];\n",
    " \n",
    "  // Calculate NDVI before January and after\n",
    "  let ndvi_before = index(s2before.B08, s2before.B04);\n",
    "  let ndvi_after = index(s2after.B08, s2after.B04);\n",
    "  \n",
    "\n",
    "  // If NDVI drop between dates is more than 0.4, query S1 data,\n",
    "  // otherwise return True Color\n",
    "  if (ndvi_before > 0.4 && ndvi_after < 0.4){\n",
    "  \n",
    "     let threshold_bc = 0.005;\n",
    "      \n",
    "     // Return different dates by color\n",
    "     if (toDb(s1[1].VH) - toDb(s1[0].VH) > threshold_bc){\n",
    "        return [255/255, 0, 0] // RED\n",
    "      } else if (toDb(s1[2].VH) - toDb(s1[1].VH)  > threshold_bc){\n",
    "        return [0, 255/255, 0]\n",
    "      } else if (toDb(s1[3].VH) - toDb(s1[2].VH)  > threshold_bc){\n",
    "        return [0, 0, 255/255]\n",
    "      } else if (toDb(s1[4].VH) - toDb(s1[3].VH)  > threshold_bc){\n",
    "        return [255/255, 255/255, 255/255]\n",
    "     } else {\n",
    "       return[255/255, 153/255, 51/255]\n",
    "     }\n",
    "    } else {\n",
    "      let gain = 3;\n",
    "      return [s2after.B04 * gain, s2after.B03 * gain, s2after.B02 * gain];\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the request body\n",
    "\n",
    "When calling multiple sources of satellite data, the request body is written slightly differently to a request using a single sensor. In the following request we need to specify as inputs: the Sentinel-1 images during January, the Sentinel-2 images before and after January. The latter are called as tow seperate datasources to save the amount of images queried.\n",
    "\n",
    "In the input data section we show you two different ways of selecting the input parameters for the different data sources:\n",
    "\n",
    "- as a dictionnary, which allows more control over the parameters\n",
    "- as a `SentinelHubRequest.input_data` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = SentinelHubRequest(\n",
    "  evalscript=evalscript_data_fusion,\n",
    "  input_data=[\n",
    "    {'type': 'S1GRD',\n",
    "     \"id\": \"s1\",\n",
    "     \"dataFilter\": {\n",
    "          \"timeRange\": {\n",
    "            \"from\": \"2018-01-01T00:00:00Z\",\n",
    "            \"to\": \"2018-01-31T23:59:59Z\"\n",
    "          }\n",
    "        }\n",
    "    },\n",
    "    SentinelHubRequest.input_data(\n",
    "      data_source=DataSource.SENTINEL2_L2A,\n",
    "      time_interval=('2017-12-31', '2017-12-31'),        \n",
    "      other_args = {\"id\":\"s2_before\"}\n",
    "    ),\n",
    "    SentinelHubRequest.input_data(\n",
    "      data_source=DataSource.SENTINEL2_L2A,\n",
    "      time_interval=('2018-02-04', '2018-02-04'),        \n",
    "      other_args = {\"id\":\"s2_after\"}\n",
    "    ),\n",
    "    \n",
    "  ],\n",
    "  responses=[\n",
    "    SentinelHubRequest.output_response('default', MimeType.TIFF),\n",
    "    \n",
    "  ],\n",
    "  bbox=aoi,  \n",
    "  size=aoi_size,\n",
    "  config=config\n",
    ")\n",
    "datafusion_results = request.get_data() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the resulting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18, 10))\n",
    "\n",
    "# Plot the image\n",
    "ax.imshow(datafusion_results[0])\n",
    "\n",
    "# Plot configuration\n",
    "for axs in [ax, ax1]:\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "    \n",
    "patches = [mpatches.Patch(color=\"orange\", label=\"2018-01-01 - 2018-01-02\"),\n",
    "           mpatches.Patch(facecolor=\"white\", edgecolor=\"black\", label=\"2018-01-02 - 2018-01-13\") ,\n",
    "           mpatches.Patch(color=\"blue\", label=\"2018-01-13 - 2018-01-14\"),\n",
    "           mpatches.Patch(color=\"lime\", label=\"2018-01-14 - 2018-01-25\"),\n",
    "           mpatches.Patch(color=\"red\", label=\"2018-01-25 - 2018-01-26\")]\n",
    "\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), title=\"Deforestation timing:\", loc=2, borderaxespad=0. )\n",
    "\n",
    "ax.set_title(\"Deforestation detection with Sentinel-1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts about automated detection of deforestation events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen previously, the manual delineation of deforested parcels using optical images presents a number of challenges. Furthermore, the method requires significant efforts and time to be scaled up to larger areas. To investigate the potential of automated detection of deforestation, we will make use of the FIS (Feature Info Service) to extract Sentinel-2 derived variables over a given time period.\n",
    "\n",
    "In the following steps, we will query NDVI values over the entire time-series of available Sentinel-2 data in order to investigate trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we select a test field from our dataset. We choose a field that was fully forested in December 2017 and fully cleared in February 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a test field\n",
    "field = gran_chaco_subset_2018[gran_chaco_subset_2018[\"field_id\"] == 88025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the field\n",
    "IPython.display.GeoJSON(field.__geo_interface__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sentinel Hub Python package also allows to use FIS. In the following steps we will build several requests in order to investigate the data in logical steps.\n",
    "\n",
    "In the first request we will query NDVI for the period `2015-01-01` to `2018-02-14`. The request looks a lot like the `SentinelHubRequest` previously used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request NDVI until February 2018\n",
    "fis_request = FisRequest(layer='NDVI',\n",
    "                         geometry_list=[Geometry(field.geometry.values[0], crs=CRS.WGS84)],\n",
    "                         time=('2015-01-01', '2018-02-14'),\n",
    "                         resolution='10m',\n",
    "                         data_folder='./data',\n",
    "                         maxcc=0.1,\n",
    "                         config=config\n",
    "                         )\n",
    "ndvi = fis_request.get_data(save_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the results of our first request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ndvi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIS request returns a list of dictionnaries and is difficult to read. To make the results more readable, we created a small function to convert the resutls to a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fis_data_to_dataframe(fis_data):\n",
    "    \"\"\" Creates a DataFrame from list of FIS responses\n",
    "    \"\"\"\n",
    "    COLUMNS = ['date', 'min', 'max', 'mean', 'stDev']\n",
    "    data = []\n",
    "    nb = 0\n",
    "    for fd in fis_data:\n",
    "        for channel, channel_stats in fd.items():\n",
    "            for stat in channel_stats:\n",
    "                row = [dt.strptime(stat['date'], \"%Y-%m-%d\")]\n",
    "                for column in COLUMNS[1:]:\n",
    "                    row.append(stat['basicStats'][column])\n",
    "                    data.append(row)\n",
    "        nb+=1\n",
    "\n",
    "    return pd.DataFrame(data, columns=COLUMNS).sort_values(['date']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the FIS results to a dataframe\n",
    "ndvi_df = fis_data_to_dataframe(ndvi)\n",
    "\n",
    "# Drop a date (visually identified as hazy)\n",
    "ndvi_df.drop(ndvi_df.loc[ndvi_df['date']==\"2016-12-01\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we plot the results of the first request, nicely formatted in a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build a second request that runs from February 2018 to today, to see how NDVI evolves after deforestation has happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the request after deforestation\n",
    "fis_request = FisRequest(layer='NDVI',\n",
    "                         geometry_list=[Geometry(field.geometry.values[0], crs=CRS.WGS84)],\n",
    "                         time=('2018-02-14', dt.today()),\n",
    "                         resolution='10m',\n",
    "                         data_folder='./data',\n",
    "                         maxcc=0.05,\n",
    "                         config=config\n",
    "                         )\n",
    "\n",
    "# Run the request\n",
    "ndvi_updated = fis_request.get_data(save_data=False)\n",
    "\n",
    "# Convert the results to a dataframe\n",
    "ndvi_df_updated = fis_data_to_dataframe(ndvi_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are interested in comparing the temporal evolution of NDVI to that of a parcel that was not deforested. To do so, we selected an area that was still forested in September 2020>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select a parcel of forest of approximately the same size of our field for comparison purposes\n",
    "forest = [ -60.19555112, -21.23150358, -60.18345680, -21.22224216]\n",
    "aoi_forest = BBox(bbox=forest, crs=CRS.WGS84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the request\n",
    "fis_request = FisRequest(layer='NDVI',\n",
    "                         geometry_list=[aoi_forest],\n",
    "                         time=('2015-01-01', dt.today()),\n",
    "                         resolution='10m',\n",
    "                         maxcc=0.05,\n",
    "                         config=config\n",
    "                         )\n",
    "# Run the request\n",
    "forest_patch = fis_request.get_data(save_data=False)\n",
    "\n",
    "# Convert the results to a dataframe\n",
    "forest_df = fis_data_to_dataframe(forest_patch)\n",
    "\n",
    "# Drop a date (visually identified as hazy)\n",
    "forest_df.drop(forest_df.loc[forest_df['date']==\"2018-09-12\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the mean NDVI of the selected field over the date range\n",
    "\n",
    "Now our data is ready, we can plot it in steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup subplots\n",
    "fig = plt.figure(figsize=(18,14))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "ax = fig.add_subplot(gs[1, :])\n",
    "ax2 = fig.add_subplot(gs[0, 0])\n",
    "ax2.set_title('gs[1, :-1]')\n",
    "ax3 = fig.add_subplot(gs[0, 1])\n",
    "ax3.set_title('gs[1, :-1]')\n",
    "\n",
    "###########\n",
    "# 1. Plot the rasters of the field as a reminder\n",
    "show(raster_before, ax=ax2)\n",
    "ax2.set_title(dt.strftime(available_datetimes[before_ind], \"%Y-%m-%d\"))\n",
    "show(raster_after, ax=ax3)\n",
    "ax3.set_title(dt.strftime(available_datetimes[after_ind], \"%Y-%m-%d\"))\n",
    "\n",
    "# 2. Plot the mean NDVI until the deforestation\n",
    "ndvi_df.plot(x='date', y='mean', ax=ax, linestyle='-', marker='.', label=r\"Mean NDVI of the field $\\pm 1\\sigma$\" )\n",
    "\n",
    "# Plot the standard deviation as a shaded area\n",
    "ax.fill_between(ndvi_df.date,\n",
    "                (ndvi_df[\"mean\"] - ndvi_df[\"stDev\"]),\n",
    "                (ndvi_df[\"mean\"] + ndvi_df[\"stDev\"]),\n",
    "                alpha=0.3)\n",
    "\n",
    "# Highlight before and after dates\n",
    "ax.scatter([\"2017-12-31\", \"2018-02-04\"], [ndvi_df[ndvi_df[\"date\"]==\"2017-12-31\"][\"mean\"], ndvi_df[ndvi_df[\"date\"]==\"2018-02-04\"][\"mean\"]], marker=\"o\", s=65, color=\"red\")\n",
    "\n",
    "###########\n",
    "\n",
    "# 2. Plot period after the identified deforestation event\n",
    "# ndvi_df_updated.plot(x='date', y='mean', ax=ax, linestyle='-', marker='.',\n",
    "#                      color=\"indianred\", label=\"Period after deforestation\" )\n",
    "# ax.fill_between(ndvi_df_updated.date, ndvi_df_updated[\"mean\"] - ndvi_df_updated[\"stDev\"],\n",
    "#                 ndvi_df_updated[\"mean\"] + ndvi_df_updated[\"stDev\"],\n",
    "#                 alpha=0.3, color=\"indianred\")\n",
    "\n",
    "###########\n",
    "\n",
    "# 3. Plot dry season months\n",
    "# ax.fill_between((\"2015-08-01\", \"2015-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n",
    "# ax.fill_between((\"2016-08-01\", \"2016-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n",
    "# ax.fill_between((\"2017-08-01\", \"2017-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n",
    "# ax.fill_between((\"2018-08-01\", \"2018-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n",
    "# ax.fill_between((\"2019-08-01\", \"2019-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n",
    "# ax.fill_between((\"2020-08-01\", \"2020-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n",
    "\n",
    "###########\n",
    "\n",
    "# 4. Plot forest patch NDVI\n",
    "# forest_df.plot(x='date', y='mean', ax=ax, linestyle='-', marker='.', color=\"forestgreen\", label=\"Patch of forest close to AOI\" )\n",
    "\n",
    "\n",
    "# Plot configuration\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"NDVI\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.tick_params(axis='both', direction='inout', )\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "ax.yaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
    "ax.yaxis.set_ticks_position(\"both\")\n",
    "\n",
    "for axs in [ax2, ax3]:\n",
    "    field.plot(ax=axs, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "    axs.set_xticks([])\n",
    "    axs.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring timeseries of satelltie imagery with FIS is an easy way to understand the data without having to query dozens of images. The figure above can lead to ideas on how to create a simple Evalscript and call Sentinel Hub services to automaticclly detect deforestation events. \n",
    "\n",
    "It is now up to you to explore the possibilities and adapt the workflow to the use case that you are particularly interested in."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EDC 0.20.1 (Python3)",
   "language": "python",
   "name": "edc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
